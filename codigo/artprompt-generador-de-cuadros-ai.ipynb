{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10311442,"sourceType":"datasetVersion","datasetId":6383292}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Desarrollar una IA generadora de cuadros que, basado en un prompt del usuario, cree una imagen en el estilo de un artista seleccionado de una lista.**\n\nEl modelo Stable Diffusion porcesa de manera mas optima en ingles el prompt, recomiendo escribirlo en ese idioma. Aun asi en español sigue pillando cosas. ","metadata":{}},{"cell_type":"markdown","source":"### Celda 1: Instalación de dependencias\nEsta celda se utiliza para instalar las bibliotecas necesarias que permitirán ejecutar el proyecto. \nLas principales librerías incluyen:\n- **diffusers**: Para trabajar con modelos de difusión, utilizados en la generación de imágenes.\n- **transformers**: Biblioteca clave para trabajar con modelos preentrenados de procesamiento de lenguaje natural y difusión.\n- **torch**: Framework de aprendizaje profundo que proporciona herramientas para crear y entrenar modelos de redes neuronales.\n- **accelerate**: Optimiza y acelera el entrenamiento en múltiples dispositivos.","metadata":{}},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"GPU disponible:\", torch.cuda.get_device_name(0))\nelse:\n    print(\"No se detectó GPU. Verifica las configuraciones en Kaggle.\")\n\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets\n\n# Actualizar e instalar las dependencias necesarias\n!pip install --upgrade diffusers transformers accelerate\n\n# Ruta del dataset\ndataset_path = '/kaggle/input/art-styles-dataset-for-ai-projects/Dataset_Cuadros'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T00:28:43.933100Z","iopub.execute_input":"2025-01-13T00:28:43.933398Z","iopub.status.idle":"2025-01-13T00:29:05.267234Z","shell.execute_reply.started":"2025-01-13T00:28:43.933367Z","shell.execute_reply":"2025-01-13T00:29:05.266088Z"}},"outputs":[{"name":"stdout","text":"GPU disponible: Tesla T4\nCollecting diffusers\n  Downloading diffusers-0.32.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting transformers\n  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.24.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.5)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.4.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading diffusers-0.32.1-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, diffusers, accelerate, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed accelerate-1.2.1 diffusers-0.32.1 tokenizers-0.21.0 transformers-4.48.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Celda 2: Visualización interactiva del dataset\nEsta celda permite al usuario explorar las imágenes del dataset de manera interactiva. Utiliza las siguientes herramientas:\n- **ipywidgets**: Crea una interfaz interactiva con un desplegable para seleccionar un artista.\n- **random**: Selecciona un subconjunto aleatorio de imágenes del artista elegido.\n- **matplotlib**: Muestra hasta seis imágenes seleccionadas aleatoriamente en un formato visual amigable.\n\nEl objetivo principal de esta celda es proporcionar al usuario una idea de las imágenes contenidas en el dataset y facilitar la inspección visual por artista.","metadata":{}},{"cell_type":"code","source":"import random\n\ndef show_random_images(artist):\n    artist_path = os.path.join(dataset_path, artist)\n    image_files = os.listdir(artist_path)\n    sampled_images = random.sample(image_files, min(6, len(image_files)))  # Tomar hasta 6 imágenes\n\n    fig, axes = plt.subplots(1, len(sampled_images), figsize=(15, 5))\n    for ax, img_file in zip(axes, sampled_images):\n        img_path = os.path.join(artist_path, img_file)\n        img = Image.open(img_path)\n        ax.imshow(img)\n        ax.axis('off')\n    plt.show()\n\ninteract(show_random_images, artist=widgets.Dropdown(\n    options=os.listdir(dataset_path),\n    description='Artista:',\n    style={'description_width': 'initial'}\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T00:29:05.268800Z","iopub.execute_input":"2025-01-13T00:29:05.269457Z","iopub.status.idle":"2025-01-13T00:29:05.920000Z","shell.execute_reply.started":"2025-01-13T00:29:05.269428Z","shell.execute_reply":"2025-01-13T00:29:05.919242Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"interactive(children=(Dropdown(description='Artista:', options=('Kahlo', 'Monet', 'Hokusai', 'Van_Gogh', 'Dalí…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aea9d13dd3ef425580e4767145f9e49e"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<function __main__.show_random_images(artist)>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"### Celda 3: Clase y transformaciones para preprocesamiento\nEn esta sección se define una clase personalizada llamada `ArtistDataset`, que es responsable de:\n- Cargar las imágenes desde las carpetas del dataset.\n- Aplicar transformaciones a las imágenes, como:\n  - **Redimensionar**: Cambia el tamaño de las imágenes a 512x512 píxeles para garantizar consistencia.\n  - **Conversión a tensores**: Convierte las imágenes en tensores de PyTorch.\n  - **Normalización**: Escala los valores de píxeles para que estén entre -1 y 1, lo que mejora la estabilidad del entrenamiento.\n\nEsta clase es fundamental para preparar los datos antes de entrenar el modelo.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass ArtistDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image\n\n# Transformaciones para las imágenes\ntransform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalizar entre -1 y 1\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T00:29:05.921507Z","iopub.execute_input":"2025-01-13T00:29:05.921713Z","iopub.status.idle":"2025-01-13T00:29:07.130104Z","shell.execute_reply.started":"2025-01-13T00:29:05.921695Z","shell.execute_reply":"2025-01-13T00:29:07.129471Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Celda 4: Entrenamiento del modelo\nEn esta celda se lleva a cabo el entrenamiento del modelo utilizando un dataset de artistas. \n#### Principales pasos:\n1. **Definición del dataset**: Se crea un dataset etiquetado que asigna una etiqueta única a cada estilo de artista.\n2. **Modelo**: El modelo utilizado es una red neuronal simple con capas totalmente conectadas. Aunque es funcional, esta arquitectura puede ser limitada para tareas complejas.\n3. **Entrenamiento**:\n   - Se optimizan los pesos del modelo usando `Adam` como optimizador.\n   - Se mide el error con la pérdida de entropía cruzada (`CrossEntropyLoss`).\n   - Un programador de tasa de aprendizaje reduce el aprendizaje cuando la pérdida no mejora.\n4. **Resultados**: Durante cada época, se calcula la pérdida promedio para evaluar el progreso del entrenamiento.\n\nEsta celda está diseñada para entrenar un modelo básico y puede ser mejorada utilizando arquitecturas de redes neuronales convolucionales (CNN) o transfer learning.","metadata":{}},{"cell_type":"code","source":"from torch import nn, optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport os\nimport torch\n\n# Dataset con etiquetas reales\nclass ArtistDataset(Dataset):\n    def __init__(self, dataset_path, transform=None):\n        self.image_paths = []\n        self.labels = []\n        self.transform = transform\n        self.label_map = {artist: i for i, artist in enumerate(os.listdir(dataset_path))}\n        \n        # Asignar etiquetas según la carpeta\n        for artist, label in self.label_map.items():\n            artist_path = os.path.join(dataset_path, artist)\n            for image_file in os.listdir(artist_path):\n                if image_file.endswith('.jpg'):\n                    self.image_paths.append(os.path.join(artist_path, image_file))\n                    self.labels.append(label)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Transformaciones para las imágenes\ntransform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])\n\n# Función de entrenamiento\ndef train_model(dataset_path, epochs=20, batch_size=16, initial_lr=0.0001):\n    # Crear dataset y dataloader\n    dataset = ArtistDataset(dataset_path, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    # Modelo\n    model = nn.Sequential(\n        nn.Flatten(),\n        nn.Linear(512 * 512 * 3, 256),\n        nn.ReLU(),\n        nn.Linear(256, len(os.listdir(dataset_path)))  # Clasificar estilos\n    )\n    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n\n    # Entrenamiento\n    for epoch in range(epochs):\n        epoch_loss = 0.0\n        for images, labels in dataloader:\n            images = images.view(images.size(0), -1)\n            labels = labels.to(torch.long)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n\n        avg_loss = epoch_loss / len(dataloader)\n        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n        scheduler.step(avg_loss)\n\n    return model\n\n# Entrenar el modelo con etiquetas reales\nmodel = train_model(dataset_path, epochs=20, batch_size=16, initial_lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T00:29:07.131477Z","iopub.execute_input":"2025-01-13T00:29:07.131899Z","iopub.status.idle":"2025-01-13T00:31:23.627229Z","shell.execute_reply.started":"2025-01-13T00:29:07.131866Z","shell.execute_reply":"2025-01-13T00:31:23.626392Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Loss: 6.2433\nEpoch 2/20, Loss: 1.7233\nEpoch 3/20, Loss: 0.6066\nEpoch 4/20, Loss: 0.4865\nEpoch 5/20, Loss: 0.2419\nEpoch 6/20, Loss: 0.0008\nEpoch 7/20, Loss: 0.0005\nEpoch 8/20, Loss: 0.0014\nEpoch 9/20, Loss: 0.0080\nEpoch 10/20, Loss: 0.0007\nEpoch 11/20, Loss: 0.0005\nEpoch 12/20, Loss: 0.0004\nEpoch 13/20, Loss: 0.0001\nEpoch 14/20, Loss: 0.0001\nEpoch 15/20, Loss: 0.0000\nEpoch 16/20, Loss: 0.0000\nEpoch 17/20, Loss: 0.0000\nEpoch 18/20, Loss: 0.0000\nEpoch 19/20, Loss: 0.0000\nEpoch 20/20, Loss: 0.0000\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Celda 5: Generación y comparación de imágenes\nEn esta sección se implementa la generación de nuevas imágenes basadas en prompts utilizando Stable Diffusion. \n#### Desglose:\n1. **Carga del modelo Stable Diffusion**:\n   - Se utiliza el modelo `stable-diffusion-v1-4` preentrenado.\n   - La configuración de \"slicing\" optimiza el uso de memoria durante la generación.\n2. **Generación de imágenes**:\n   - Combina un estilo de artista seleccionado por el usuario con un prompt descriptivo para crear una nueva imagen.\n3. **Comparación visual**:\n   - Se seleccionan al azar imágenes de referencia del dataset para compararlas con la imagen generada.\n   - Se muestra una gráfica con la imagen generada y las referencias, facilitando la comparación.\n4. **Interactividad**:\n   - Widgets permiten al usuario elegir un artista y escribir un prompt antes de generar una imagen.\n\nEsta celda es crucial para mostrar los resultados finales y evaluar la calidad de las imágenes generadas en comparación con los estilos del dataset original.","metadata":{}},{"cell_type":"code","source":"!pip install diffusers[torch] transformers accelerate\nfrom diffusers import StableDiffusionPipeline\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\npipeline = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\npipeline.enable_attention_slicing()\n\ndef generate_and_compare(artist, prompt):\n    full_prompt = f\"A painting in the style of {artist}: {prompt}\"\n    generated_image = pipeline(full_prompt).images[0]\n\n    artist_path = os.path.join(dataset_path, artist)\n    reference_images = random.sample(os.listdir(artist_path), min(2, len(os.listdir(artist_path))))\n\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n    axes[0].imshow(generated_image)\n    axes[0].set_title(\"Generated\")\n    axes[0].axis('off')\n\n    for i, ref_image in enumerate(reference_images):\n        img_path = os.path.join(artist_path, ref_image)\n        img = Image.open(img_path)\n        axes[i + 1].imshow(img)\n        axes[i + 1].set_title(f\"Reference {i + 1}\")\n        axes[i + 1].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\nfrom ipywidgets import Button, Output, VBox\n\n# Crear widgets para artista y prompt\nartist_dropdown = widgets.Dropdown(options=os.listdir(dataset_path), description='Artista:')\nprompt_input = widgets.Text(value='', description='Prompt:')\nbutton = Button(description=\"Generar Imagen\")\noutput = Output()\n\ndef on_button_click(b):\n    with output:\n        output.clear_output()\n        generate_and_compare(artist_dropdown.value, prompt_input.value)\n\nbutton.on_click(on_button_click)\n\n# Mostrar widgets y botón\nVBox([artist_dropdown, prompt_input, button, output])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T00:31:23.628087Z","iopub.execute_input":"2025-01-13T00:31:23.628377Z","iopub.status.idle":"2025-01-13T00:32:26.714524Z","shell.execute_reply.started":"2025-01-13T00:31:23.628356Z","shell.execute_reply":"2025-01-13T00:32:26.713454Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.48.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: diffusers[torch] in /usr/local/lib/python3.10/dist-packages (0.32.1)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (8.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (3.16.1)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (0.24.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (0.4.5)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (10.4.0)\nRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]) (2.4.1+cu121)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[torch]) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[torch]) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[torch]) (3.1.4)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers[torch]) (3.20.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[torch]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[torch]) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[torch]) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->diffusers[torch]) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->diffusers[torch]) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be00047842d043d8ac6858d9464b4ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a89721a7c5f64869b51d8c65f488e334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cef91d3ce2e43369167918bb626e98d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba40ceb01ccc48c3bf09c838cc2d4739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3d4f4c483234adc92be0987c3fc066b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"safety_checker/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb9e542966354954a6cdde26b7b1d4bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77b9af5c899b454497be468e0242852e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f717cf424f4e0281a4041acaa113b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c059e49d5554753a78bf199a68bd656"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c4e6102926b40d6b3f6bf45b00b0955"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)kpoints/scheduler_config-checkpoint.json:   0%|          | 0.00/209 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545d4cfb47bb48b48698e356a8012444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca16db5cc1d4306a7e59536b9769aac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db4b91037a0d48f48f66674ca5c4f334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b486f42f39c0468cae5853159dec6d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e875523e14847b8a73ea7d086676c72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b7915c45af340ec9eeb82a177898836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8258015135934d76b4978dd52398f00a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78a25849a7e4b6da3f4912fc09f043d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f0440814b24cf29aa87f72e9f801ce"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"VBox(children=(Dropdown(description='Artista:', options=('Kahlo', 'Monet', 'Hokusai', 'Van_Gogh', 'Dalí', 'Pic…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fcad4245af64c0c8a3e48b5d77cc3fb"}},"metadata":{}}],"execution_count":5}]}